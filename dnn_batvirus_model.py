"""
This script is used to process input X and Y
"""
import numpy as np
import os
import string
import re 
import keras
import tensorflow as tf
from sklearn.model_selection import train_test_split
from keras.layers import Dense, Dropout
import pandas as pd


def get_data(x_file = 'virus_data/X_data.npy', y_file = 'virus_data/Y_data.npy'):
    
    X = np.load(x_file) # load the matrix data generated by data.py
    Y = np.load(y_file) # y_test is lable 1 yes or 0 no

    X_train = X
    X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0) # will change r_state for each loop
    X_train, X_valid, Y_train, Y_valid = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=12345)

    return X_train, Y_train, X_valid, Y_valid, X_test, Y_test, X, Y

def set_up_model(X_train, Y_train, X_valid, Y_valid):

    input_shape = 51
    #data_input = Input(shape = input_shape, name = 'data_input') # for API architecture

    model = keras.Sequential()
    model.add(Dense(32, input_dim = input_shape, activation = 'relu'))
    model.add(Dense(32, activation = 'relu')) # saved h5 uses architecture of 16,8,8,6
    model.add(Dense(16, activation = 'relu'))
    model.add(Dense(16, activation = 'relu'))
    model.add(Dense(8, activation = 'relu'))
    model.add(Dropout(0.50))
    model.add(Dense(1, activation = 'sigmoid'))

    return model

if __name__ == '__main__':
    n_estimators = 50
    Y_predict = []
    Y_acc = []
    bagging_acc = []
    models = [] # save trained model 'RMSprop' 'SGD' 'adam' 'nadam'
    Y_pred = [] # save overall prediction from the top models
    for i in range(n_estimators):
        X_train, Y_train, X_valid, Y_valid, X_test, Y_test, X, Y = get_data()
        model = set_up_model(X_train, Y_train, X_valid, Y_valid)
        #model.summary()
        
        model.compile(loss = 'binary_crossentropy', optimizer = 'nadam', metrics = ['accuracy']) # multi-label classification
        my_callbacks = [keras.callbacks.EarlyStopping(patience=20)] # for early stopping
        model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_data=(X_valid, Y_valid), callbacks = my_callbacks)
        preds = model.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)
        print("Loss = " + str(preds[0]) + " Test Accuracy = " + str(preds[1]))
        
        X_cov19 = (pd.read_csv('SARS_related_CoV_representative_pseudoinput.csv')).values # dnn_cov19virus_binary_pseudoinput.csv EPI_ISL_402131_binary_pseudoinput
        pred = model.predict(X_cov19)
        #pred = model.predict((np.reshape(X,(-1, 51)))) # X[27], [33], [xx] is sars virus for 2, 4, 6 group division
        Y_predict.append(pred)
        Y_acc.append(preds[1])
        models.append(model)

    sorted_acc_id = np.argsort(Y_acc) # sort test accuracy in ascending order and return their index
    best_model_id = sorted_acc_id[int(0.8 * n_estimators):n_estimators]
    for i in best_model_id: # iterate the id list
        Y_pred.append(Y_predict[i])
        bagging_acc.append(Y_acc[i])
    print(bagging_acc)
    Y_pred = np.mean(Y_pred, axis = 0)
    bagging_acc = np.mean(bagging_acc) # purely a mean value across models and doesn't reflect the accuracy of bagging prediction

    print(Y_pred)
    print("Bagging Accuracy = " + str(bagging_acc))
